{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import plot_tree, export_text\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use url, but can also download and access it locally\n",
    "dataset_path = 'https://raw.githubusercontent.com/Koldim2001/test_api/refs/heads/main/titanic.csv' \n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Survived', 'Pclass', 'Age', 'Fare']]  # The subset (columns) we selected for this project\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Survived')  # These are our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitdataset\n",
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Plots confusion matrix\n",
    "    cm - confusion matrix\n",
    "    classes - class list\n",
    "    normalize - normalize to 1 if True\n",
    "    title - plot title\n",
    "    cmap - color map\n",
    "    \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(max_depth, min_samples_split):\n",
    "    \"\"\"\n",
    "    Builds and trains Decision Tree model\n",
    "    \"\"\"\n",
    "    # Build and train Decision Tree model\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, random_state=42)\n",
    "    model.fit(train.drop('Survived', axis=1), train['Survived'])\n",
    "\n",
    "    # Calculate accuracy metrics\n",
    "    preds = model.predict(test.drop('Survived', axis=1))\n",
    "    acc = accuracy_score(test['Survived'], preds)\n",
    "    cm = confusion_matrix(test['Survived'], preds)\n",
    "\n",
    "    print(\"accuracy\", acc)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(cm, classes=['Not Survived', 'Survived'])\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(test['Survived'], preds, target_names=['Not Survived', 'Survived'])\n",
    "    print(report)\n",
    "\n",
    "    # Save model in pickle format\n",
    "    with open('../outputs/models/model_dt.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model hyperparameters\n",
    "max_depth = 5\n",
    "min_samples_split = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(max_depth, min_samples_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from pkl\n",
    "with open('../outputs/models/model_dt.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict outcome of Titanic trip for a person\n",
    "person = pd.DataFrame({\n",
    "\t'Pclass':[3],\n",
    "\t'Age':[55],\n",
    "\t'Fare':[7.2500]\t\n",
    "})\n",
    "\n",
    "prediction = model.predict(person)\n",
    "print(f\"The model predicts {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prediction == [1]:\n",
    "    print (\"This person is, the most likely, is a survivor.\")\n",
    "else:\n",
    "    print(\"This person, the most likely, perished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,20))\n",
    "plot_tree(model, feature_names=df.drop(columns='Survived').columns, max_depth=5, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_text = export_text(model, max_depth=5, feature_names=df.drop(columns='Survived').columns)\n",
    "print(tree_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame({\n",
    "    'feature': df.drop(columns='Survived').columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "plt.title('Feature Importance')\n",
    "sns.barplot(data=importance_df.head(10), x='importance', y='feature', hue='importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_depth_error(md):\n",
    "    \"\"\"\n",
    "    Returns training and validation (test) accuracy as a function of tree maximum depth\n",
    "    \"\"\"\n",
    "    model = DecisionTreeClassifier(max_depth=md, random_state=42)\n",
    "    model.fit(train.drop(columns='Survived'), train['Survived'])\n",
    "    train_acc = 1 - model.score(train.drop(columns='Survived'), train['Survived'])\n",
    "    test_acc = 1 - model.score(test.drop(columns='Survived'), test['Survived'])\n",
    "    return {'Max Depth': md, 'Training Error': train_acc, 'Test Error': test_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_list = []\n",
    "\n",
    "for md in range(1, 21):\n",
    "    result = max_depth_error(md)\n",
    "    errors_list.append(result)\n",
    "\n",
    "errors_df = pd.DataFrame(errors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(errors_df['Max Depth'], errors_df['Training Error'])\n",
    "plt.plot(errors_df['Max Depth'], errors_df['Test Error'])\n",
    "plt.title('Training vs. Validation Error')\n",
    "plt.xticks(range(0,21, 2))\n",
    "plt.xlabel('Max. Depth')\n",
    "plt.ylabel('Prediction Error (1 - Accuracy)')\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?DecisionTreeClassifier"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
